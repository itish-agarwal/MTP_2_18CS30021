{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d953be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J', 'Z', 'K', 'Q', 'I', 'N', 'O', 'G', 'D', 'C', 'Y', 'U', 'T', 'H', 'S', 'A', 'F', 'W', 'V', 'E', 'P', 'L', 'B', 'R', 'X', 'M']\n",
      "Types of classes labels found:  26\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "dataset_path = os.listdir('../aRDee/mydata/training_set')\n",
    "\n",
    "print (dataset_path)  #what kinds of classes are in this dataset\n",
    "\n",
    "print(\"Types of classes labels found: \", len(dataset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c432683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "model = EfficientNetB0 (weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6da38918",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = []\n",
    "path = r\"../aRDee/mydata/training_set\"\n",
    "\n",
    "for item in dataset_path:\n",
    " # Get all the file names\n",
    " all_classes = os.listdir(path + '/' +item)\n",
    "#  print(all_classes)\n",
    "\n",
    " # Add them to the list\n",
    " for room in all_classes:\n",
    "    class_labels.append((item, str('dataset_path' + '/' +item) + '/' + room))\n",
    "    #print(class_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e328a961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Labels                    image\n",
      "0      J   dataset_path/J/913.png\n",
      "1      J   dataset_path/J/174.png\n",
      "2      J   dataset_path/J/239.png\n",
      "3      J  dataset_path/J/1267.png\n",
      "4      J   dataset_path/J/726.png\n",
      "      Labels                    image\n",
      "45495      M     dataset_path/M/8.png\n",
      "45496      M  dataset_path/M/1706.png\n",
      "45497      M  dataset_path/M/1018.png\n",
      "45498      M   dataset_path/M/825.png\n",
      "45499      M   dataset_path/M/992.png\n"
     ]
    }
   ],
   "source": [
    "# Build a dataframe        \n",
    "df = pd.DataFrame(data=class_labels, columns=['Labels', 'image'])\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3097f393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images in the dataset:  45500\n",
      "J    1750\n",
      "Z    1750\n",
      "X    1750\n",
      "R    1750\n",
      "B    1750\n",
      "L    1750\n",
      "P    1750\n",
      "E    1750\n",
      "V    1750\n",
      "W    1750\n",
      "F    1750\n",
      "A    1750\n",
      "S    1750\n",
      "H    1750\n",
      "T    1750\n",
      "U    1750\n",
      "Y    1750\n",
      "C    1750\n",
      "D    1750\n",
      "G    1750\n",
      "O    1750\n",
      "N    1750\n",
      "I    1750\n",
      "Q    1750\n",
      "K    1750\n",
      "M    1750\n",
      "Name: Labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Let's check how many samples for each category are present\n",
    "print(\"Total number of images in the dataset: \", len(df))\n",
    "\n",
    "label_count = df['Labels'].value_counts()\n",
    "print(label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf3daff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J\n",
      "Z\n",
      "K\n",
      "Q\n",
      "I\n",
      "N\n",
      "O\n",
      "G\n",
      "D\n",
      "C\n",
      "Y\n",
      "U\n",
      "T\n",
      "H\n",
      "S\n",
      "A\n",
      "F\n",
      "W\n",
      "V\n",
      "E\n",
      "P\n",
      "L\n",
      "B\n",
      "R\n",
      "X\n",
      "M\n"
     ]
    }
   ],
   "source": [
    "# Resize images\n",
    "\n",
    "import cv2\n",
    "path = \"../aRDee/mydata/training_set/\"\n",
    "dataset_path = os.listdir(\"../aRDee/mydata/training_set/\")\n",
    "\n",
    "im_size = 96\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for i in dataset_path:\n",
    "    print(i)\n",
    "    data_path = path + str(i)  \n",
    "    filenames = [i for i in os.listdir(data_path) ]\n",
    "   \n",
    "    for f in filenames:\n",
    "        img = cv2.imread(data_path + '/' + f)\n",
    "        img = cv2.resize(img, (im_size, im_size))\n",
    "        images.append(img)\n",
    "        labels.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29f9b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6269eab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60c15801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45500, 96, 96, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This model takes input images of shape (224, 224, 3), and the input data should range [0, 255]. \n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "images = images.astype('float32') / 255.0\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "984250f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J' 'J' 'J' ... 'M' 'M' 'M']\n",
      "[ 9  9  9 ... 12 12 12]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "y = df['Labels'].values\n",
    "print(y)\n",
    "\n",
    "y_labelencoder = LabelEncoder ()\n",
    "y = y_labelencoder.fit_transform (y)\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02d77298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7367a254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36400, 96, 96, 3)\n",
      "(36400, 26)\n",
      "(9100, 96, 96, 3)\n",
      "(9100, 26)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(images, y, test_size=0.2)\n",
    "\n",
    "#inpect the shape of the training and testing.\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "707f4297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1 )\n",
    "# test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip= True,zoom_range=.1)\n",
    "\n",
    "# train_generator.fit(train_x)\n",
    "# test_generator.fit(test_x)\n",
    "\n",
    "# #Learning Rate Annealer\n",
    "# from keras.callbacks import ReduceLROnPlateau\n",
    "# lrr= ReduceLROnPlateau( monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b607c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "NUM_CLASSES = 26\n",
    "IMG_SIZE = 224\n",
    "size = (IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "outputs = EfficientNetB0(include_top = True, weights = None, classes = NUM_CLASSES) (inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eda0823",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EfficientNetB0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m IMG_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m224\u001b[39m\n\u001b[0;32m----> 2\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mEfficientNetB0\u001b[49m(include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(IMG_SIZE,IMG_SIZE,\u001b[38;5;241m3\u001b[39m),classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m26\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EfficientNetB0' is not defined"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "base_model = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(IMG_SIZE,IMG_SIZE,3),classes=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "087d1584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb5 (Functional)  (None, 7, 7, 2048)       28513527  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100352)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              102761472 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 131,799,799\n",
      "Trainable params: 131,627,056\n",
      "Non-trainable params: 172,743\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "model.add(base_model) \n",
    "model.add(Flatten()) \n",
    "\n",
    "#Adding the Dense layers along with activation and batch normalization\n",
    "model.add(Dense(1024,activation=('relu'),input_dim=512))\n",
    "\n",
    "model.add(Dense(512,activation=('relu'))) \n",
    "# model.add(Dense(256,activation=('relu'))) \n",
    "# #model.add(Dropout(.3))\n",
    "# model.add(Dense(128,activation=('relu')))\n",
    "# #model.add(Dropout(.2))\n",
    "# model.add(Dense(29,activation=('softmax'))) \n",
    "\n",
    "#Checking the final model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "239969f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sukanya/.local/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "learn_rate=.001\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a4bd7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471a0a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Rate Annealer\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "lrr= ReduceLROnPlateau( monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)\n",
    "\n",
    "\n",
    "#Defining the parameters\n",
    "batch_size= 32\n",
    "epochs=2\n",
    "learn_rate=.001\n",
    "model.fit(train_x, train_y, batch_size = batch_size, epochs = epochs, steps_per_epoch = train_x.shape[0]//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cad8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99213e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a35276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637abd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5114b707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
